{
  "Severity": "MODERATE",
  "UpdatedAt": "2026-02-11T15:13:23Z",
  "Package": {
    "Ecosystem": "NPM",
    "Name": "@langchain/community"
  },
  "Advisory": {
    "DatabaseId": 336742,
    "Id": "GSA_kwCzR0hTQS1nZjN2LWZ3cWctNHZoN84ABSNm",
    "GhsaId": "GHSA-gf3v-fwqg-4vh7",
    "References": [
      {
        "Url": "https://github.com/langchain-ai/langchainjs/security/advisories/GHSA-gf3v-fwqg-4vh7"
      },
      {
        "Url": "https://github.com/langchain-ai/langchainjs/pull/9990"
      },
      {
        "Url": "https://github.com/langchain-ai/langchainjs/commit/d5e3db0d01ab321ec70a875805b2f74aefdadf9d"
      },
      {
        "Url": "https://github.com/langchain-ai/langchainjs/releases/tag/%40langchain%2Fcommunity%401.1.14"
      },
      {
        "Url": "https://nvd.nist.gov/vuln/detail/CVE-2026-26019"
      },
      {
        "Url": "https://github.com/advisories/GHSA-gf3v-fwqg-4vh7"
      }
    ],
    "Identifiers": [
      {
        "Type": "GHSA",
        "Value": "GHSA-gf3v-fwqg-4vh7"
      },
      {
        "Type": "CVE",
        "Value": "CVE-2026-26019"
      }
    ],
    "Description": "## Description\n\nThe `RecursiveUrlLoader` class in `@langchain/community` is a web crawler that recursively follows links from a starting URL. Its `preventOutside` option (enabled by default) is intended to restrict crawling to the same site as the base URL.\n\nThe implementation used `String.startsWith()` to compare URLs, which does not perform semantic URL validation. An attacker who controls content on a crawled page could include links to domains that share a string prefix with the target (e.g., `https://example.com.attacker.com` passes a `startsWith` check against `https://example.com`), causing the crawler to follow links to attacker-controlled or internal infrastructure.\n\nAdditionally, the crawler performed no validation against private or reserved IP addresses. A crawled page could include links targeting cloud metadata services (`169.254.169.254`), localhost, or RFC 1918 addresses, and the crawler would fetch them without restriction.\n\n## Impact\n\nAn attacker who can influence the content of a page being crawled (e.g., by placing a link on a public-facing page, forum, or user-generated content) could cause the crawler to:\n\n- Fetch cloud instance metadata (AWS, GCP, Azure), potentially exposing IAM credentials and session tokens\n- Access internal services on private networks (`10.x`, `172.16.x`, `192.168.x`)\n- Connect to localhost services\n- Exfiltrate response data via attacker-controlled redirect chains\n\nThis is exploitable in any environment where `RecursiveUrlLoader` runs on infrastructure with access to cloud metadata or internal services â€” which includes most cloud-hosted deployments.\n\n## Resolution\n\nTwo changes were made:\n\n1. **Origin comparison replaced.** The `startsWith` check was replaced with a strict origin comparison using the URL API (`new URL(link).origin === new URL(baseUrl).origin`). This correctly validates scheme, hostname, and port as a unit, preventing subdomain-based bypasses.\n\n2. **SSRF validation added to all fetch operations.** A new URL validation module (`@langchain/core/utils/ssrf`) was introduced and applied before every outbound fetch in the crawler. This blocks requests to:\n   - **Cloud metadata endpoints:** `169.254.169.254`, `169.254.170.2`, `100.100.100.200`, `metadata.google.internal`, and related hostnames\n   - **Private IP ranges:** `10.0.0.0/8`, `172.16.0.0/12`, `192.168.0.0/16`, `127.0.0.0/8`, `169.254.0.0/16`\n   - **IPv6 equivalents:** `::1`, `fc00::/7`, `fe80::/10`\n   - **Non-HTTP/HTTPS schemes** (`file:`, `ftp:`, `javascript:`, etc.)\n\nCloud metadata endpoints are unconditionally blocked and cannot be overridden.\n\n## Workarounds\n\nUsers who cannot upgrade immediately should avoid using `RecursiveUrlLoader` on untrusted or user-influenced content, or should run the crawler in a network environment without access to cloud metadata or internal services.",
    "Origin": "UNSPECIFIED",
    "PublishedAt": "2026-02-11T15:13:20Z",
    "Severity": "MODERATE",
    "Summary": "@langchain/community affected by SSRF Bypass in RecursiveUrlLoader via insufficient URL origin validation",
    "UpdatedAt": "2026-02-12T14:19:07Z",
    "WithdrawnAt": "",
    "CVSS": {
      "Score": 4.1,
      "VectorString": "CVSS:3.1/AV:N/AC:L/PR:L/UI:R/S:C/C:L/I:N/A:N"
    }
  },
  "Versions": [
    {
      "FirstPatchedVersion": {
        "Identifier": "1.1.14"
      },
      "VulnerableVersionRange": "\u003c= 1.1.13"
    }
  ]
}